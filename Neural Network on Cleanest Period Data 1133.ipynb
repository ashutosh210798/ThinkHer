{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avani/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/avani/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/avani/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/avani/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/avani/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/avani/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/avani/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.6) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from math import floor, ceil\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data = pd.read_csv('newData.csv')\n",
    "#clean_data['period_noPeriod'] = clean_data['period_noPeriod']*100+clean_data['period_noPeriod']\n",
    "#clean_data['date']=pd.to_datetime(clean_data['date']) \n",
    "#lean_data['date']=pd.to_numeric(clean_data['date'])\n",
    "clean_data=pd.read_csv(\"comb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#X = clean_data.drop('period_noPeriod', 1)\n",
    "#X.fillna(0,inplace=True)\n",
    "y = clean_data['cycle_length_initial']\n",
    "X = clean_data.drop(['cycle_length_initial'], axis=1)\n",
    "#y = clean_data['period_noPeriod']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,learning_rate_init=0.1,\n",
    "                     activation='relu',learning_rate='adaptive',solver='adam', verbose=10,  random_state=0,tol=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.22595852\n",
      "Iteration 2, loss = 1.56852060\n",
      "Iteration 3, loss = 1.56899237\n",
      "Iteration 4, loss = 1.56965376\n",
      "Iteration 5, loss = 1.56951245\n",
      "Iteration 6, loss = 1.57034451\n",
      "Iteration 7, loss = 1.57053772\n",
      "Iteration 8, loss = 1.57070747\n",
      "Iteration 9, loss = 1.57068426\n",
      "Iteration 10, loss = 1.57117981\n",
      "Iteration 11, loss = 1.57042328\n",
      "Iteration 12, loss = 1.57015307\n",
      "Iteration 13, loss = 1.57083652\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_x, train_y)\n",
    "y_pred = clf.predict(test_x)\n",
    "\n",
    "# def multilayer_perceptron(x, weights, biases, keep_prob):\n",
    "#     layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "#     layer_1 = tf.nn.relu(layer_1)\n",
    "#     layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "#     out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "#     return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.570084485407066"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_epochs = 5000\n",
    "# display_step = 1000\n",
    "# batch_size = 32\n",
    "\n",
    "# x = tf.placeholder(\"float\", [None, n_input])\n",
    "# y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = multilayer_perceptron(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "#     for epoch in range(training_epochs):\n",
    "#         avg_cost = 0.0\n",
    "#         total_batch = int(len(train_x) / batch_size)\n",
    "#         x_batches = np.array_split(train_x, total_batch)\n",
    "#         y_batches = np.array_split(train_y, total_batch)\n",
    "#         for i in range(total_batch):\n",
    "#             batch_x, batch_y = x_batches[i], y_batches[i]\n",
    "# #             _, c = sess.run([optimizer, cost], \n",
    "# #                             feed_dict={\n",
    "# #                                 x: batch_x, \n",
    "# #                                 y: batch_y, \n",
    "# #                                 keep_prob: 0.8\n",
    "# #                             })\n",
    "# #             avg_cost += c / total_batch\n",
    "#         if epoch % display_step == 0:\n",
    "#             print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "#                 \"{:.9f}\".format(avg_cost))\n",
    "#     print(\"Optimization Finished!\")\n",
    "#     correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#     print(\"Accuracy:\", accuracy.eval({x: test_x, y: test_y, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
